{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = Image.open('photo.out/10002463616318_АО62399.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=148x38 at 0x7FA78A7D27D0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max = [306  90] ; min =  [58 13] ; average =  [144.31223051  38.28872554]\n"
     ]
    }
   ],
   "source": [
    "photo_size = []\n",
    "for n in os.listdir('photo.out/'):\n",
    "    photo_size.append(Image.open('photo.out/' + n).size)\n",
    "\n",
    "print('max =', np.array(photo_size).max(axis=0), '; min = ', np.array(photo_size).min(axis=0),\n",
    "     '; average = ', np.average(np.array(photo_size), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipg_to_numpy(path):\n",
    "    image = Image.open(path)\n",
    "    image.load()\n",
    "    return np.asarray(image, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = np.array([38, 124]).astype(np.int32)\n",
    "\n",
    "def padding_image(image, image_shape = image_shape):\n",
    "    shape = image.shape\n",
    "    \n",
    "    if len(shape) == 3:\n",
    "        image = np.average(image, axis=2)\n",
    "        shape = image.shape\n",
    "        \n",
    "    for i in range(image_shape[0] - shape[0]):\n",
    "        image = np.vstack((image, np.zeros((1, shape[1]))))\n",
    "\n",
    "    for i in range(image_shape[1] - shape[1]):\n",
    "        image = np.hstack((image, np.zeros((image_shape[0], 1))))\n",
    "        \n",
    "    return image.astype(np.float32)\n",
    "\n",
    "\n",
    "allowed_token = ['', 'А', 'В', 'Е', 'К', 'М', 'Н', 'О', 'Р', 'С', 'Т', 'У', 'Х'] + [str(x) for x in  range(10)]\n",
    "vocab_size = len(allowed_token)\n",
    "\n",
    "token_dict_incode = {y:x for x,y in zip(range(vocab_size), allowed_token)}\n",
    "token_dict_decode = {x:y for x,y in zip(range(vocab_size), allowed_token)}\n",
    "\n",
    "def parser_fn(image, regno, token_dict = token_dict_incode, image_shape = image_shape):\n",
    "\n",
    "    label = []\n",
    "    for tok in regno:\n",
    "        label.append(token_dict[tok])\n",
    "    for i in range(len(regno), 9):\n",
    "        label.append(token_dict[''])\n",
    "    label = np.array(label).astype(np.int32)\n",
    "   \n",
    "    #feature = padding_image(image)[:,:, np.newaxis]\n",
    "    if len(image.shape) == 3:\n",
    "        image = np.average(image, axis=2)\n",
    "    feature = image[:,:, np.newaxis]\n",
    "    \n",
    "    return feature, (label, len(label))\n",
    "\n",
    "def jpg_to_numpy(path):\n",
    "    image = Image.open(path)\n",
    "    image.load()\n",
    "#    return np.asarray(image, dtype=np.float32)\n",
    "    return np.asarray(image.resize((image_shape[1],image_shape[0])), dtype=np.float32)\n",
    "\n",
    "def generator_fn(csv_path, image_path):\n",
    "    \n",
    "    with open(csv_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        head = next(csv_reader)\n",
    "        csv_head = {x: y for x,y in zip(head, range(len(head)))}\n",
    "        csv_row_i = 0\n",
    "        for row in csv_reader:\n",
    "            csv_row_i += 1\n",
    "            tr_check_id = row[csv_head['tr_check_id']]\n",
    "            regno = row[csv_head['regno']]\n",
    "            image = jpg_to_numpy(image_path + f'/{tr_check_id}_{regno}.jpg')\n",
    "            yield parser_fn(image, regno)\n",
    "\n",
    "\n",
    "def input_fn(params, mode):\n",
    "\n",
    "    shapes = ([image_shape[0],image_shape[1],1], ([None], ()))\n",
    "    types = (tf.float32, (tf.int32, tf.int32))\n",
    "    defaults = (0., (0, 0))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(lambda : generator_fn(params['csv_path'], params['image_path']),\n",
    "                                             output_shapes=shapes,\n",
    "                                             output_types=types)\n",
    "    \n",
    "\n",
    "    if mode == 'train':\n",
    "#        dataset = dataset.shuffle(buffer_size=params['train_size'], reshuffle_each_iteration=True)\n",
    "        dataset = dataset.repeat(params['num_epochs'])\n",
    "#        dataset = dataset.repeat()\n",
    "\n",
    "    return dataset.padded_batch(params['batch_size'], shapes, defaults).prefetch(params['train_size'])    \n",
    "\n",
    "\n",
    "def test_input_fn(csv_path, image_path, params):\n",
    "    '''функция подачи данных в модель для теста\n",
    "        на вход получает массив строк'''\n",
    "    shapes = ([image_shape[0],image_shape[1],1], ([None], ()))\n",
    "    types = (tf.float32, (tf.int32, tf.int32))\n",
    "    defaults = (0., (0, 0))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(lambda : generator_fn(csv_path, image_path),\n",
    "                                             output_shapes=shapes, output_types=types)\n",
    "    \n",
    "    return dataset.padded_batch(params['batch_size'], shapes, defaults).prefetch(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = generator_fn(params['csv_path'], params['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "К347КК197\n",
      "[ 4 16 17 20  4  4 14 22 20]\n"
     ]
    }
   ],
   "source": [
    "q = next(a)[1][0]\n",
    "regno = ''\n",
    "for t in q:\n",
    "        regno += token_dict_decode[t]\n",
    "print(regno)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель\n",
    "def model_fn(features, labels, mode, params):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=features,\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, 7, 4)\n",
    "    \n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(conv2, 5, 3)\n",
    "\n",
    "    \n",
    "    reduce_max = tf.math.reduce_max(pool2, 1)\n",
    "\n",
    "    \n",
    "    dense1 = tf.layers.dense(reduce_max, params['output_vocab_size'])\n",
    "#    denses = []\n",
    "    \n",
    "#    for _ in range(params['length_regno']):\n",
    "#        dense = tf.layers.dense(dense1, params['output_vocab_size'])\n",
    "#        denses += [dense]\n",
    "    \n",
    "#    logits = tf.stack(denses, axis=1)\n",
    "    logits = dense1\n",
    "    #logits = tf.math.argmax(dense1,2)\n",
    "    \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'prediction': logits,\n",
    "        }\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    else:\n",
    "        target, target_lengths = labels\n",
    "        print(target)\n",
    "\n",
    "        mask = tf.sequence_mask(target_lengths, dtype=tf.float32)\n",
    "\n",
    "\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(logits=logits, \n",
    "                                                targets=target, \n",
    "                                                weights = mask,\n",
    "                                                average_across_timesteps=True, \n",
    "                                                average_across_batch=True)\n",
    "\n",
    "        # в режиме eval возвращаем усреднённый лосс\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            mask = tf.sequence_mask(lengths, dtype=tf.float32)\n",
    "            metrics = {\n",
    "                'acc': tf.metrics.accuracy(target, sample_id, mask),\n",
    "                'f1_score' : tf.contrib.metrics.f1_score(tf.one_hot(target, 7), \n",
    "                                                     tf.one_hot(sample_id, 7), mask),\n",
    "            }\n",
    "            \n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        # в режиме train ещё и обновляем обучаемые параметры\n",
    "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer\n",
    "            optimizer = optimizer(learning_rate=params['learning_rate'])\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pro', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa7433e5190>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'length_regno': 9,\n",
    "    'output_vocab_size': vocab_size,\n",
    "    'train_size': 10,\n",
    "    'num_layers': 2,\n",
    "    'dropout_rate': 0.2,\n",
    "    'lstm_hidden_dim': 512,\n",
    "    'max_iter': 10,\n",
    "    'batch_size': 5,\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 1e-3,\n",
    "    'csv_path': 'data.csv',\n",
    "    'image_path': 'photo.out'\n",
    "}\n",
    "\n",
    "config = tf.estimator.RunConfig(model_dir='pro',\n",
    "                                save_checkpoints_steps = 1000,\n",
    "                               save_checkpoints_secs = None)\n",
    "model = tf.estimator.Estimator(model_fn=model_fn, params=params, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, ?), dtype=int32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into pro/model.ckpt.\n",
      "INFO:tensorflow:loss = 72.75542, step = 1\n",
      "INFO:tensorflow:global_step/sec: 53.4541\n",
      "INFO:tensorflow:loss = 2.7129157, step = 101 (1.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.2147\n",
      "INFO:tensorflow:loss = 2.6860154, step = 201 (1.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.1543\n",
      "INFO:tensorflow:loss = 2.7682056, step = 301 (1.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.4112\n",
      "INFO:tensorflow:loss = 2.6400275, step = 401 (1.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.9699\n",
      "INFO:tensorflow:loss = 2.576481, step = 501 (1.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5355\n",
      "INFO:tensorflow:loss = 2.4487295, step = 601 (1.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5105\n",
      "INFO:tensorflow:loss = 2.0903893, step = 701 (1.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.4944\n",
      "INFO:tensorflow:loss = 2.2358184, step = 801 (1.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.3916\n",
      "INFO:tensorflow:loss = 2.0614855, step = 901 (1.874 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 52.8394\n",
      "INFO:tensorflow:loss = 2.0433133, step = 1001 (1.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.071\n",
      "INFO:tensorflow:loss = 2.3916917, step = 1101 (1.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1903\n",
      "INFO:tensorflow:loss = 1.8104335, step = 1201 (1.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2086\n",
      "INFO:tensorflow:loss = 1.8301413, step = 1301 (1.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.5401\n",
      "INFO:tensorflow:loss = 1.7033896, step = 1401 (1.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2257\n",
      "INFO:tensorflow:loss = 2.0671039, step = 1501 (1.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2977\n",
      "INFO:tensorflow:loss = 1.795144, step = 1601 (1.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.6883\n",
      "INFO:tensorflow:loss = 2.606925, step = 1701 (1.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2723\n",
      "INFO:tensorflow:loss = 1.7110994, step = 1801 (1.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7507\n",
      "INFO:tensorflow:loss = 1.1457547, step = 1901 (1.794 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 55.0285\n",
      "INFO:tensorflow:loss = 1.7182105, step = 2001 (1.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.4747\n",
      "INFO:tensorflow:loss = 2.0656419, step = 2101 (1.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8315\n",
      "INFO:tensorflow:loss = 1.3017995, step = 2201 (1.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.2539\n",
      "INFO:tensorflow:loss = 1.3659135, step = 2301 (1.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2017\n",
      "INFO:tensorflow:loss = 1.7815291, step = 2401 (1.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.344\n",
      "INFO:tensorflow:loss = 1.1645993, step = 2501 (1.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1931\n",
      "INFO:tensorflow:loss = 1.0541046, step = 2601 (1.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8812\n",
      "INFO:tensorflow:loss = 0.8867607, step = 2701 (1.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.697\n",
      "INFO:tensorflow:loss = 1.5506219, step = 2801 (1.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.6707\n",
      "INFO:tensorflow:loss = 0.9178917, step = 2901 (1.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 54.3794\n",
      "INFO:tensorflow:loss = 1.2943983, step = 3001 (1.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.542\n",
      "INFO:tensorflow:loss = 1.8761737, step = 3101 (1.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7891\n",
      "INFO:tensorflow:loss = 1.5992509, step = 3201 (1.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8924\n",
      "INFO:tensorflow:loss = 0.79481965, step = 3301 (1.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.2746\n",
      "INFO:tensorflow:loss = 0.9953102, step = 3401 (2.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4314\n",
      "INFO:tensorflow:loss = 0.67496204, step = 3501 (1.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0997\n",
      "INFO:tensorflow:loss = 0.9789824, step = 3601 (1.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4576\n",
      "INFO:tensorflow:loss = 1.5647761, step = 3701 (1.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2538\n",
      "INFO:tensorflow:loss = 1.0786978, step = 3801 (1.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2227\n",
      "INFO:tensorflow:loss = 1.9166778, step = 3901 (1.844 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 52.0533\n",
      "INFO:tensorflow:loss = 0.45411733, step = 4001 (1.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.741\n",
      "INFO:tensorflow:loss = 1.092501, step = 4101 (1.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9065\n",
      "INFO:tensorflow:loss = 1.3019738, step = 4201 (1.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.1133\n",
      "INFO:tensorflow:loss = 2.5699277, step = 4301 (2.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7227\n",
      "INFO:tensorflow:loss = 1.5074209, step = 4401 (1.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5878\n",
      "INFO:tensorflow:loss = 1.7559742, step = 4501 (2.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.3036\n",
      "INFO:tensorflow:loss = 0.6374775, step = 4601 (2.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1162\n",
      "INFO:tensorflow:loss = 0.8074221, step = 4701 (2.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.4123\n",
      "INFO:tensorflow:loss = 0.63265115, step = 4801 (2.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9976\n",
      "INFO:tensorflow:loss = 1.3608235, step = 4901 (2.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 43.0112\n",
      "INFO:tensorflow:loss = 0.5792869, step = 5001 (2.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9174\n",
      "INFO:tensorflow:loss = 0.123458005, step = 5101 (2.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5752\n",
      "INFO:tensorflow:loss = 1.6610236, step = 5201 (2.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7696\n",
      "INFO:tensorflow:loss = 0.9084761, step = 5301 (1.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.9833\n",
      "INFO:tensorflow:loss = 1.3803624, step = 5401 (1.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2861\n",
      "INFO:tensorflow:loss = 1.3815466, step = 5501 (1.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1318\n",
      "INFO:tensorflow:loss = 0.5890391, step = 5601 (1.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.361\n",
      "INFO:tensorflow:loss = 2.043265, step = 5701 (1.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1436\n",
      "INFO:tensorflow:loss = 1.3099669, step = 5801 (1.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.8217\n",
      "INFO:tensorflow:loss = 0.5815794, step = 5901 (1.893 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 52.5415\n",
      "INFO:tensorflow:loss = 1.4745797, step = 6001 (1.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5031\n",
      "INFO:tensorflow:loss = 0.65316206, step = 6101 (1.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7849\n",
      "INFO:tensorflow:loss = 2.1285813, step = 6201 (1.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2905\n",
      "INFO:tensorflow:loss = 0.40203756, step = 6301 (1.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.2802\n",
      "INFO:tensorflow:loss = 1.5024707, step = 6401 (1.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0407\n",
      "INFO:tensorflow:loss = 0.7409186, step = 6501 (1.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0971\n",
      "INFO:tensorflow:loss = 1.33756, step = 6601 (1.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.576\n",
      "INFO:tensorflow:loss = 0.71880174, step = 6701 (1.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0311\n",
      "INFO:tensorflow:loss = 0.38891166, step = 6801 (1.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.9542\n",
      "INFO:tensorflow:loss = 0.63727844, step = 6901 (1.819 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 54.3071\n",
      "INFO:tensorflow:loss = 1.0065942, step = 7001 (1.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2819\n",
      "INFO:tensorflow:loss = 0.42471802, step = 7101 (1.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9753\n",
      "INFO:tensorflow:loss = 1.787256, step = 7201 (1.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9188\n",
      "INFO:tensorflow:loss = 0.91230553, step = 7301 (1.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.5838\n",
      "INFO:tensorflow:loss = 0.37026027, step = 7401 (1.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.9254147, step = 7501 (1.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9962\n",
      "INFO:tensorflow:loss = 0.81839955, step = 7601 (1.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9358\n",
      "INFO:tensorflow:loss = 0.34752607, step = 7701 (1.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.4071\n",
      "INFO:tensorflow:loss = 1.0120044, step = 7801 (1.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0168\n",
      "INFO:tensorflow:loss = 0.16741192, step = 7901 (1.818 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 54.8281\n",
      "INFO:tensorflow:loss = 0.5288395, step = 8001 (1.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.823\n",
      "INFO:tensorflow:loss = 0.5721882, step = 8101 (1.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0083\n",
      "INFO:tensorflow:loss = 0.3689471, step = 8201 (1.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1114\n",
      "INFO:tensorflow:loss = 0.3799561, step = 8301 (1.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0424\n",
      "INFO:tensorflow:loss = 0.8317301, step = 8401 (1.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.4838\n",
      "INFO:tensorflow:loss = 1.2641526, step = 8501 (1.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8926\n",
      "INFO:tensorflow:loss = 0.41570953, step = 8601 (1.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9117\n",
      "INFO:tensorflow:loss = 0.9187644, step = 8701 (1.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.229\n",
      "INFO:tensorflow:loss = 0.5698308, step = 8801 (1.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9511\n",
      "INFO:tensorflow:loss = 0.41773427, step = 8901 (1.789 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 54.8458\n",
      "INFO:tensorflow:loss = 0.8594075, step = 9001 (1.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.8915\n",
      "INFO:tensorflow:loss = 0.28171706, step = 9101 (1.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.1988\n",
      "INFO:tensorflow:loss = 0.49858436, step = 9201 (1.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.3143\n",
      "INFO:tensorflow:loss = 0.8437823, step = 9301 (1.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8212\n",
      "INFO:tensorflow:loss = 1.7905904, step = 9401 (1.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.76\n",
      "INFO:tensorflow:loss = 0.40519255, step = 9501 (1.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.9745\n",
      "INFO:tensorflow:loss = 1.121027, step = 9601 (1.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.589\n",
      "INFO:tensorflow:loss = 1.388251, step = 9701 (1.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0989\n",
      "INFO:tensorflow:loss = 0.51554334, step = 9801 (1.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5934\n",
      "INFO:tensorflow:loss = 1.3210398, step = 9901 (1.866 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 49.7757\n",
      "INFO:tensorflow:loss = 0.73705506, step = 10001 (2.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5728\n",
      "INFO:tensorflow:loss = 0.68168366, step = 10101 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.259\n",
      "INFO:tensorflow:loss = 0.16923226, step = 10201 (1.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.0548\n",
      "INFO:tensorflow:loss = 0.39093968, step = 10301 (1.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.2106\n",
      "INFO:tensorflow:loss = 0.6989379, step = 10401 (1.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.4155\n",
      "INFO:tensorflow:loss = 0.38706696, step = 10501 (1.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8149\n",
      "INFO:tensorflow:loss = 0.6023317, step = 10601 (2.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1107\n",
      "INFO:tensorflow:loss = 0.88729596, step = 10701 (1.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4967\n",
      "INFO:tensorflow:loss = 0.6130159, step = 10801 (1.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7087\n",
      "INFO:tensorflow:loss = 0.7458525, step = 10901 (1.897 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 52.7939\n",
      "INFO:tensorflow:loss = 0.42045704, step = 11001 (1.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.75\n",
      "INFO:tensorflow:loss = 1.1023235, step = 11101 (2.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.8765\n",
      "INFO:tensorflow:loss = 0.4776407, step = 11201 (1.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.6564\n",
      "INFO:tensorflow:loss = 0.21098286, step = 11301 (1.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7199\n",
      "INFO:tensorflow:loss = 0.691492, step = 11401 (1.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.6308\n",
      "INFO:tensorflow:loss = 0.43040696, step = 11501 (1.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.0113\n",
      "INFO:tensorflow:loss = 0.46893278, step = 11601 (1.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3033\n",
      "INFO:tensorflow:loss = 3.0234747, step = 11701 (1.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.9958\n",
      "INFO:tensorflow:loss = 0.69418854, step = 11801 (1.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3801\n",
      "INFO:tensorflow:loss = 0.33427256, step = 11901 (1.984 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 52.9085\n",
      "INFO:tensorflow:loss = 1.7739868, step = 12001 (1.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.1815\n",
      "INFO:tensorflow:loss = 0.56805253, step = 12101 (1.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.7629\n",
      "INFO:tensorflow:loss = 0.8483301, step = 12201 (1.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.5013\n",
      "INFO:tensorflow:loss = 0.70872617, step = 12301 (1.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.788\n",
      "INFO:tensorflow:loss = 0.6620153, step = 12401 (1.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8493\n",
      "INFO:tensorflow:loss = 1.3979182, step = 12501 (1.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6061\n",
      "INFO:tensorflow:loss = 0.16998717, step = 12601 (1.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.8089\n",
      "INFO:tensorflow:loss = 0.48258418, step = 12701 (1.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2486\n",
      "INFO:tensorflow:loss = 0.6305356, step = 12801 (1.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.5536\n",
      "INFO:tensorflow:loss = 0.9675423, step = 12901 (1.769 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 54.6722\n",
      "INFO:tensorflow:loss = 0.79518825, step = 13001 (1.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.5749\n",
      "INFO:tensorflow:loss = 0.7803865, step = 13101 (1.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5514\n",
      "INFO:tensorflow:loss = 2.6970198, step = 13201 (1.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3676\n",
      "INFO:tensorflow:loss = 0.9066953, step = 13301 (1.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.932\n",
      "INFO:tensorflow:loss = 0.15813936, step = 13401 (2.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5202\n",
      "INFO:tensorflow:loss = 0.3563932, step = 13501 (2.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7593\n",
      "INFO:tensorflow:loss = 0.6177538, step = 13601 (2.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4712\n",
      "INFO:tensorflow:loss = 0.65741414, step = 13701 (2.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.6034\n",
      "INFO:tensorflow:loss = 1.156317, step = 13801 (2.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9852\n",
      "INFO:tensorflow:loss = 0.8304273, step = 13901 (2.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 43.9586\n",
      "INFO:tensorflow:loss = 0.3666989, step = 14001 (2.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3013\n",
      "INFO:tensorflow:loss = 0.8695103, step = 14101 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5713\n",
      "INFO:tensorflow:loss = 0.60745335, step = 14201 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0199\n",
      "INFO:tensorflow:loss = 0.3887669, step = 14301 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9331\n",
      "INFO:tensorflow:loss = 0.26414075, step = 14401 (1.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.972\n",
      "INFO:tensorflow:loss = 0.39325994, step = 14501 (1.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.7126\n",
      "INFO:tensorflow:loss = 0.7740097, step = 14601 (1.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0038\n",
      "INFO:tensorflow:loss = 0.5695975, step = 14701 (1.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.5448\n",
      "INFO:tensorflow:loss = 0.8451522, step = 14801 (1.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6516\n",
      "INFO:tensorflow:loss = 0.51172155, step = 14901 (2.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 51.0685\n",
      "INFO:tensorflow:loss = 0.6311061, step = 15001 (1.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2197\n",
      "INFO:tensorflow:loss = 0.6417338, step = 15101 (1.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.7571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8237899, step = 15201 (2.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2982\n",
      "INFO:tensorflow:loss = 0.4682217, step = 15301 (1.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8916\n",
      "INFO:tensorflow:loss = 0.4118527, step = 15401 (1.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9199\n",
      "INFO:tensorflow:loss = 0.5070522, step = 15501 (1.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.2408\n",
      "INFO:tensorflow:loss = 1.506153, step = 15601 (1.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.4858\n",
      "INFO:tensorflow:loss = 0.78040534, step = 15701 (1.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0174\n",
      "INFO:tensorflow:loss = 0.75313365, step = 15801 (1.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8286\n",
      "INFO:tensorflow:loss = 0.73658645, step = 15901 (1.791 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 53.5959\n",
      "INFO:tensorflow:loss = 0.7229275, step = 16001 (1.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5566\n",
      "INFO:tensorflow:loss = 1.1639333, step = 16101 (1.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8284\n",
      "INFO:tensorflow:loss = 0.6176432, step = 16201 (1.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.7482\n",
      "INFO:tensorflow:loss = 1.1369249, step = 16301 (1.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5923\n",
      "INFO:tensorflow:loss = 0.82827324, step = 16401 (1.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.1473\n",
      "INFO:tensorflow:loss = 0.7779882, step = 16501 (1.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.1721\n",
      "INFO:tensorflow:loss = 0.7418209, step = 16601 (1.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.473\n",
      "INFO:tensorflow:loss = 0.38010198, step = 16701 (2.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.4566\n",
      "INFO:tensorflow:loss = 1.0949544, step = 16801 (1.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.9473\n",
      "INFO:tensorflow:loss = 0.615124, step = 16901 (1.756 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 54.8049\n",
      "INFO:tensorflow:loss = 1.0619171, step = 17001 (1.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1776\n",
      "INFO:tensorflow:loss = 0.48879513, step = 17101 (1.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.1102\n",
      "INFO:tensorflow:loss = 0.23086245, step = 17201 (1.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.3573\n",
      "INFO:tensorflow:loss = 0.32851234, step = 17301 (2.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.5983\n",
      "INFO:tensorflow:loss = 0.3649788, step = 17401 (1.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.7079\n",
      "INFO:tensorflow:loss = 0.6692537, step = 17501 (1.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.807\n",
      "INFO:tensorflow:loss = 0.9476521, step = 17601 (1.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.7832\n",
      "INFO:tensorflow:loss = 0.31229672, step = 17701 (1.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5531\n",
      "INFO:tensorflow:loss = 1.706598, step = 17801 (1.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0669\n",
      "INFO:tensorflow:loss = 0.6411292, step = 17901 (2.038 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 46.4737\n",
      "INFO:tensorflow:loss = 0.50644654, step = 18001 (2.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7917\n",
      "INFO:tensorflow:loss = 0.6052199, step = 18101 (2.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.247\n",
      "INFO:tensorflow:loss = 0.9232967, step = 18201 (2.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.8973\n",
      "INFO:tensorflow:loss = 0.5501374, step = 18301 (2.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6415\n",
      "INFO:tensorflow:loss = 0.46648437, step = 18401 (2.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.2175\n",
      "INFO:tensorflow:loss = 0.9350225, step = 18501 (2.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8219\n",
      "INFO:tensorflow:loss = 0.76437676, step = 18601 (2.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7259\n",
      "INFO:tensorflow:loss = 0.72982943, step = 18701 (2.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.775\n",
      "INFO:tensorflow:loss = 1.960203, step = 18801 (2.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8722\n",
      "INFO:tensorflow:loss = 0.52828944, step = 18901 (2.046 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into pro/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 49.6297\n",
      "INFO:tensorflow:loss = 0.46347407, step = 19001 (2.015 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f602f26855b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(lambda: input_fn(params=params, mode='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-7-d410dd60e77b>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-d410dd60e77b>:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-d410dd60e77b>:26: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pro/model.ckpt-19000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "К038ОО19\n",
      "scor:\n",
      "[1.0, 0.8925811, 0.9878182, 0.9999466, 0.77878296, 0.99996185, 1.0, 0.99862385, 0.8230029, ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=159x41 at 0x7FA743FFAED0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def fprediction(photo_url):\n",
    "    image = jpg_to_numpy(photo_url)\n",
    "        \n",
    "    #feature = padding_image(image)[:,:, np.newaxis]\n",
    "    if len(image.shape) == 3:\n",
    "        image = np.average(image, axis=2)\n",
    "    feature = image[:,:, np.newaxis]\n",
    "   \n",
    "    prediction = next(model.predict(lambda: tf.data.Dataset.from_tensors(np.array([feature])) ))\n",
    "    regno = ''\n",
    "    for t in prediction['prediction'].argmax(axis=1):\n",
    "        regno += token_dict_decode[t]\n",
    "        \n",
    "    photo = Image.open(photo_url)\n",
    "    print(regno)\n",
    "    print('scor:')\n",
    "    print('[', end='')\n",
    "    for scor in softmax(prediction['prediction'], axis=1).max(axis=1):\n",
    "        print(scor, end=', ')\n",
    "    print(']')\n",
    "    return photo\n",
    "\n",
    "fprediction('test.out/10002465555101_К038РО197.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pro/model.ckpt-19000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "М707УХ177\n",
      "scor:\n",
      "[0.9542531, 0.6529092, 0.7864285, 0.9998131, 0.99552774, 0.99998665, 0.98356926, 0.995579, 0.9784517, ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=119x23 at 0x7FA743ACF890>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprediction('test.out/160002169085324_М707УХ177.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pro/model.ckpt-19000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "М528ВС777\n",
      "scor:\n",
      "[0.99998474, 0.9928616, 1.0, 0.99158037, 0.9999962, 0.99999046, 1.0, 0.99996185, 0.8383408, ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKUAAAAsCAAAAAAh/ycWAAAP3UlEQVR4nJVZWcxd11Vea+3hDHf857+OXTuOEztpYidx6sxN6kYVHUIRVRAUHihqhUQl4JFHJJ5AvPCEKgRCaqWCKE2hA4SSUtqU2hmdOI7tOB7i2f94/zucae+9Fg/33t/+fzsd1svRPeeevdf+1vwd/DiBsAAhDCWMrgIbRTZdAyASIvDoN296jusvChCIENxa8Fa3EICERQBREBC0CAIA4matfpEgwoZ3brEbAAAQAyIKb7yLN6Ewfn98n0fqIiCAFgEARNy0zC8U2rDm+PfGXQCGp0G8AdrRzh+sJQIIAgMSgACBjLREQNz8718kCCAgIJu1u8niN2kBGzbcjCGOfvHwaIKCAnq8yni3XxZTBPmlvEREAGDoVyMtflkgrovGYQSsb/grLYFygyU3XjdHywbsBGQzltdFYGjpkbFAhloKCMivGj2yaYfNll/XbpNfkoCMvG+DXLclCggAgTAAAgMC6KGDiHyQP/18wQ/0w/X7JEA3QIsowLfAZLPHkQgIAAoKgqbh+UCQEIQFMGhfTeYkw3AsURGKiBJGhMBEKAxGV5odGHQUwEDFygQfxsfmUXDIGDtEcNTosXVK91XM4lolisKCJgKoYDCzjape8lyWLxZmwLaMhqmHMADcED2IAiAIIGIgcCBABBBJRAAUUYaIIDg0oAQutCKtGW3hkQgw01YJs3hARAJQI7eKYJhFJnp+0tR7KQSjQXmIFGGAJMVBTRc2oTzSTSK4enQhIMEo3sbxeT3GBRgQSHGIkSxrRAQR0QAiwhArRSACDolIQqgTCBGbOGJrkSEQCZPWwKKNEgFUWmmiCElrranEUg+2L+skd4WdmA5iUvK1hmwvpqLS2TzVvTSsTV5d6/QQRYARCGTkANexBBYAQtBmO0SpGCICZmZtVCiyKjVaDZMKao3B1yD4QFqJkFbA7AFQaaNcYG01hwlS2mhFFpU2VpNtnTh2/umpRhZSgjxdStlyGduB2D4bL7aj20hWz912IigRgGHR5mE+XtdyLOXE3FO1RqQsEgGztLXVXOZVpBQBAKTMpJEDEEkQayuEwEA4QB0ZdE77oIwKHoYWh2jk36vqIzPndnQXmxWAX0vjy2tZVXgJn6+++060Vppy/otJapdrLRLyQhvDa13LsR/QxB2PJ1FJZmTxCgjJ1IBEiEDYCAMCoBbSUnGlgBmtgQRccCKgUCEKUCQgIgIIAiIoU64fws9eXin7uown/kD/w+qq0cu8dW/5xvFZdv1V31QRhBgDqhKJx3GCG7Qc+0FUb80AlTTujSIRQFIolQ+avHdKkYiA6hVRqtghiNaU9azREETbCkAYQAaAiIjoAJCIMM9sY/7s0mWj/Hm1q86zrZk2HV6Z3qGeG0Tc/cGpGd0PDvqFVxi0CuM42YTlyA9QvPcWkwpEABEYCYWdDPICjHJVPUoMCuDqldX6bW2rHQCGztlz3Q/vmY+q4JCGnYKMYhxBmBHQilqrP/oQKffu19837eorlNc77sjW0tzVzFV2qHlbxEm3lRcBkYX8OE4EAECv9y7AAKggayUsoDlYvWrqPaMKP5HFmf+LfMWIj6Tl/951Zta+80b/vH9oz+dSJJ+c/v6rA4ezB34HEvC624CysRzXFicHMZVkS058lXqIL+0qjLLu/uftQeeJAleX4NeJm1fm+Wi38STqol7oXHOpsTQFEYI41gB4Q4wLAIBgZFMNUoHqxareQ1ulflnFjaPFNc1xbEo921MzC9//Tt6cil8+sfqnWdRb+bsT2YNr/cuv7Xy8KGocSUBol6vtUNQW511pTBnFFbN3IQB26oc62x9GEyTQxf6eiBw0s3hx5Z5Y1qwNeRiVXoWE64X0eoyPMmjwRogIZUJMYakPPmqaNbO4SL939+1GDVSoZ/DSj/CzH9/xyj8tH331Hlf79/Pplw7o9772pj5gJ11hHUOvkRoMsUoclZb6oTmIgb0XgqDf7h1sD4i8Lt4Mj8boubbqTpWfnPVxHU3swlAZQsRhndyQL2Xknhx5RKGQX9o1aBYqppxDYqNJ/Ois7VmMipWkOpp99DmV7E/++v239zr4mTz0rKeP7Dm7VMvx3RNlj5Ns8oE9mbZV63Ln0LvR9nv3TDiGIKSwfm2h/mjFCqvGe0fm92oA4Oj4mdu2S5HiIGuVDCC43jOhbMISBAQw0Q0mDiLfuPJbd/V9u+P/563kD6fOVBoVMRgHNlmu7b1npndtbveE75e0oDrbihLFJhadO/G95aBaPfXKcw9I8J0j/0Ydf/Z/D/y+RQmMKObQpQe3dCMbPB69+hszlWjo2zf7B1sEnRC1bBlARgOOrPcsN2EZQgxaGXvtJ4PwR3Gr3z586NTOSbAGzydTsZGAxunfnjOrE4W8UflF2zNan16+DS5eXp3tp6rbn3mwYVdOnfjWvdzAr5+kT+3sv/Ufb13+MENgJd4f6z0BMZeKFo+17kMBxdXKyZn9ixPHns8+tb9TDS3OG3rATbVHMHCMxKU6K/zSli9gfvX5U9VUVaAb/PO22fadW2I0DqfyTiM37nxn6jNRPm/sT5oH3j93rPUE2byndn+hHsoXV08tT9DZw8mfzaLc82AxP3QzlHcXd+4oWfXT+LXz92wtEYOLX1p+eAvS4lvFkwlXw7Fs1BOOOsPN0SNpUqMwWLQXYMAvfLaY+f6xuIOsdcEnL5Z+584/yTwlVM541/zaf2WP7Vhp476r8s3DeqXcs1+kQoBUpDUXYW/ryg/cM7MgOtrLUVCktAY60nmMqDOnQ3qyvytxlpjrx/0dVip7e5iUkod2FhIUGM+pen3mG9VbzETnf3sy3tKvlb2/+uKPf9iq4rbJprf3G/10bfHslb/0EFTUabuvvp7d/bmWx4pDpgtTpBev7AaxRXZ1Or78en9mysXn6tslWHAW+o2lSaJuvXepfjDqTmW2vHB5+25CdFH37aK1l4n3N+tbYnBpj4xHVsACSJsq5Fi4Ng0LV1Yaqzwxd+HCN07KvdV7g7z+yME85sHLR18+/Td/3LNl1L7yfy+v3PHM1sj23ji8cGDf3jOnfiAv7G4kg3Dkq6ToEu2bzy/23F0JYNXHNKpSveYnstdO7ZsMqS5V9PrlA9uMD1ULjy49Pl2Iie6IzODiuI2/dX85loIt1vbtbK8sJE+eOHxCP3bg0DkyebKiAtYf2d07ddJOlT5aOfTt1XufeTwqo8HxfOdnb5+7571zl05eeMAMcPkt8VaSKfIrrpz0uY+nIOSkyQNwsfcg9mqFq4F5+GDSoyQqJp97aq4Xh8oq8uKCAIggjvuKW3duusho/lmTPv9G+mvbLrx257O3H+I0WlQt5QXjObWmj+zlJH/xv8/f9+n7bSZR92hn38ORc7MfWVg78+CqVrO7E8jPd093okkrF6eN1VyERDKf6MwceHQuAz0A7w6YtvO26tfzaLbd6beKzKMYCTxO3MO+Qm6pZQ2oTKY0mBBoxyem72uqoJVL4jDIYlW0d7ykB1ntyisvnN/3zENpVveicqdEcptEIUS69PZjv5tWp//12DuD9rzmw8/5jBIWLeKQyuZWCFVLIlyoz8CKneivgFlMMaRaVFSDgq8FBhDZNOvf3AWHus8dQkmqg598ZDpnDyrgQn9bLYjuXWun97Ec/tZK7enH0pLDWtyYX+oeu7MJy6erZDfUuQIu63vuP1lpUAm/cnCyXXXOy121SPqcyIAg4fcn61mzkFziQizU69AlySqO0OtOYACQ63PYrbGsSoVsAAdhNvVWLU2XGJQpvvvqIwebzaVXX8+2RL3Xfnp14ok7pwtRvalu2h6cflH2vnriOO+f67kLmCRJdvo9f1dtYPYvXfzmJ3ZdffHwru2RDg60lDVQ5aIf1MzCXHtJWVzVtSOwjRYaYZCjTX0YNs6Io/6Sb6llQypWOvhJT8qVpl5kMTDZ04N/Obt/6sfHZOvnVfvQu3F57h+3rjV0+LKq7Tm+8sN3ZqLj6kO/OTWAiaX/fH8KV87w3Wm3dvDY8vPHmmVWtSYrwIhKO+kGJpmounfrxcnYJdHizDv3b29wZ2cugF5TLjJmJEZz2FDLUZ6EUX7ypcIgsboSVFXLROLS0Xwovvz1Y4fPqMX49i/V9JrjQMfid6p6Z/LuT8CB/IdnLy5Y2fXpOwUoxGtv6gIbz36G4rz15W//dHnZbv/YA5UpVTWod5uYhnwLIMrWS3oKus7dR6prmwPdb4aq0aMuQgkYQABwnUO4CUuKNJV+UNbunO+DMqaqGpOhak995Sc/uqj2PPrR2dyX07u6/YgYWnPNNKe5p1pHLpbz9z85CwvSbJpgVP32Oz7cGhAW8889CtZEM3HuAJQQeQ9IRingulGJMTYj0JENzhEqLcvVUItNRBk+Pa45wgJIOLXtz2NGLWvd6SToCrVeXv5QY5DVREihd41eaq50IYtykhjVXUVFcShtnEEQE6GzofRebGSLXgv6DeNKbQJy1hh0f/bEFhYWEQ4sCQJ7BorBe8LeasySZ+WpQ2eCY7jeuW3Ccpzr01oVQXDSmsQMbNCdRiuBHNOUi1KlKfRZoNVIEbO48sa5mEIQKUItlEIcqjUb1RRUWaXqis3AT5fBQFA1NTjz/pYUSsW+KvLCd5QUgwJV6ctSQm9NU+lMWFqJ+RZc1Q3TGSAASO6WkxirkCtdJeB0XSvKoIZloDqUfUlJKhcCJp5UpThfTmOkOBTXMIrylcrEMSwtl0r1iYqgKgd9m2TdqrL982+f2kqVEgmurHyQUBaOSEkIgMGhKqQuVaNkucngN/tl9/wLs7WmjQunnZHlOMRx6HUK2OJU5NcK8s6bWDm34pt5kTpvktB1qfH1hb7VldcuIu/REA+MFyxSlWnTH3jnJ0BdvqowIAKHwMzMQIoqBAFSygFKUVV6RKFvVGrdL3lIdkvqE+ZU14qqJhTllmJXoINUgqCvmIgLSDEPsbcDtrkuoggFhDtRJIUjSyXHiWRFktW96F5iC8SSYl5oG3ROKYcAIswEgESILCDCgCVphYjghJFwE3V4E5YDcVp8qcmVeVlnLJplHgdX78eaAdmVaXBKJOp7zKJ4kEJHjBSYhNDLqQY9zVRmTiWVolWZpTJni56KYlu2FCtgN+RclWIiYCdiGIjEc9ujz5V26lZ0Lz494nNoHdPr/CPAiOWHIWkIIqJG80gQQALmIU07ZBjgBkr5JlZfhk9x9L/xcy+ChCJKBAhZjAwVCSPb3rongnWV1neR9c1ERqVBQIEgAeKQvgBBGRbdn/M164an10+jRlrKkPsdXmQdlk11fBzjo71uYPWHb6MgiMjoS4GAHk70GIZtgWzOHjd9WRmfVRBvZPFJcMibsaCICI85/2Gj8QGdG2xS8/qnAVlvqQRAvAATMI/PPK6+H4Tl+Mlo+fX1+TqWAijMI6hHY9iwRv4/XL9VStKo5hMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=165x44 at 0x7F5F33569A50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprediction('test.out/60002109049881_М528ВС777.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.8925811, 0.9878182, 0.9999466, 0.77878296, 0.99996185, 1.0, 0.99862385, 0.8230029, ]\n"
     ]
    }
   ],
   "source": [
    "print('[', end='')\n",
    "for scor in softmax(prediction['prediction'], axis=1).max(axis=1):\n",
    "    print(scor, end=', ')\n",
    "print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1442123877529815e-06"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m.exp(12) + m.exp(31)) / (m.exp(43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
